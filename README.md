# í›ˆì´ì˜ ì‹ë‹¹ ë¦¬ë·° ê°ì„± ë¶„ì„ì— ì˜¤ì‹  ê°•ì‚¬ë‹˜ì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ’•

**ì§ì ‘ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ ì½”ë“œì— í•´ë‹¹í•˜ëŠ” í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ ë¶€ë¶„ì„ ê±´ë„ˆë›°ì–´ ì£¼ì„¸ìš”. ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ ë”°ë¡œ `preprocessed_sentences`ë¥¼ ì €ì¥í•´ë†“ì•˜ìŠµë‹ˆë‹¤ (ì´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤).**

```python
from konlpy.tag import Okt
from nltk import word_tokenize, sent_tokenize
from tqdm import tqdm

okt = Okt()

preprocessed_sentences = []

for review in tqdm(reviews):
    review = re.sub(r"[^ê°€-í£0-9\s]", "", review)   # êµ¬ë‘ì , íŠ¹ìˆ˜ë¬¸ì, ì˜ë¬¸ ì œê±°
    review = re.sub(r"\s+", " ", review).strip()   # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ
    tokens = okt.morphs(review, stem=True, norm=True) # í† í°í™”
    tokens = filter_tokens(tokens)
    preprocessed_sentences.append(tokens)
```

## ê²°ê³¼

![snetiment_model_result](image/sentiment_result.png)


### 17ê¸° í™”ì´íŒ…! ê°•ì‚¬ë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤!
